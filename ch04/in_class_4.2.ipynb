{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Text Analysis: Finding Words that Uniquely Characterize a Book\n",
    "\n",
    "Relevant resources:\n",
    " * [Python & Pandas Field Guide: Chapter 4](https://snakebear.science/04-Functions/toctree.html)\n",
    "\n",
    "We're going to write some code to do a  text analysis to find words that uniquely characterize a book. \n",
    "\n",
    "In previous exercises we have counted letters or words. We're going to do some more counting here but if we only look for words that are used frequently in a book by itself, we will get a lot of common but unimportant words, like \"the,\" \"a,\" \"he,\" \"she,\" etc., that would occur in nearly any English-language book.  We can find more *interesting* important words that are unique to a specific book by excluding words that occur across books and identifying frequently occurring words unique to a specific book.\n",
    "\n",
    "The notebook below will work through this process.  We've provided some functions that handle low-level parts of the analysis.  You'll use those functions and write some of your own to perform the analysis.\n",
    "\n",
    "Goals:\n",
    "  * Practice *using* functions that take arguments and return values.\n",
    "  * Practice *writing* new functions.\n",
    "  * Work on a realistic data science task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have a cell for import statements, which is almost always the first code cell in a notebook.  For the code we've provided, we're importing the `collections` module.  You can add more import statements here if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided Functions\n",
    "\n",
    "Each of the functions here is already written and tested; they do not need to be changed.  Once you execute these cells to define the functions, you can use them below.\n",
    "\n",
    "A comment at the top of each function describes how to use it.  Read those comments.\n",
    "\n",
    "**Important:** You do not need to understand the code in any of these functions.  Remember *abstraction*: we just want to *use* the functions, and we'll *ignore* the complexity inside them.  (Feel free to look through them later if you want to, though.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "def get_words(book_filename):\n",
    "    '''\n",
    "    get_words() reads a file and returns a list of the words in that file.\n",
    "    \n",
    "    Call it with one argument: a string containing the name of the file you want to read.\n",
    "    Returns: the words in that file.\n",
    "    '''\n",
    "    with open(book_filename) as f:\n",
    "        file_contents = f.read()\n",
    "    words = file_contents.split()\n",
    "    words = [w.strip(\",.-!?'\\\";:()\") for w in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "def calc_frequencies(words):\n",
    "    '''\n",
    "    calc_frequencies() counts the frequency of every word in a list of words.\n",
    "    \n",
    "    Call it with one argument: a list of strings.\n",
    "    Returns: a collection of frequencies that you can use with get_frequency() (below).\n",
    "    '''\n",
    "    return collections.Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "def get_frequency(word, freqs):\n",
    "    '''\n",
    "    get_frequency() gets the frequency of a single word.\n",
    "    \n",
    "    Call it with two arguments:\n",
    "      1) The word whose frequency you want\n",
    "      2) A collection of frequencies produced by get_frequencies() (above).\n",
    "    Returns: The number of times that word occurs\n",
    "    '''\n",
    "    return freqs[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "def unique_words(words1, words2):\n",
    "    '''\n",
    "    unique_words() finds words that are unique to one book compared to another.\n",
    "    \n",
    "    Call it with two arguments: each a list of words.\n",
    "    Returns: a list of words that *are* in the first list but are *not* in the second list.\n",
    "    '''\n",
    "    set1 = set(words1)\n",
    "    set2 = set(words2)\n",
    "    return list(set1 - set2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Try out the functions\n",
    "\n",
    "We need to try out the functions to learn how each works before we can use them together.  Read the comment inside each function definition above for guidance on how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_words()`\n",
    "\n",
    "First, get lists of the words in two different books using `get_words()`.  The books available are:\n",
    "  * *A Tale of Two Cities* in file `atotc.txt`\n",
    "  * *Pride and Prejudice* in file `pandp.txt`\n",
    "  * *Alice's Adventures in Wonderland* in file `alice.txt`\n",
    "  * *Dracula* in file `dracula.txt`\n",
    "\n",
    "Steps:\n",
    "  * Choose whichever books you like.\n",
    "  * Store one book's words in a variable `words1` and the other list in `words2`.\n",
    "  * Then, inspect the lists: look at the first 10 words in each by printing `words1[:10]` and `words2[:10]`.\n",
    "     * *Adding `[:10]` after the list variable is performing an operation called \"slicing.\"  We'll learn more about it soon.*\n",
    "  \n",
    "You should see the words of the title plus a bit more of each book you've chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try get_words() here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `calc_frequencies()` and `get_frequency()`\n",
    "\n",
    "Now try out `calc_frequencies()` and `get_frequency()`:\n",
    "  * Call `calc_frequencies()` with each of the word lists you generated above as an argument (you'll have to call it once for each list)\n",
    "  * Store the function's return value in `freqs1` and `freqs2`.\n",
    "  * Then, call `get_frequency()` to get the frequency of \"the\" in both of the books.\n",
    "  * Print out the frequency of \"the\" for both books.\n",
    "\n",
    "**Remember:** The variables you created in the cell above can be used in all later cells; you don't need to copy that code here.\n",
    "\n",
    "You should get the following frequencies for \"the\" in each book:\n",
    "  * `atotc.txt`: 7379\n",
    "  * `pandp.txt`: 4048\n",
    "  * `alice.txt`: 1515\n",
    "  * `dracula.txt`: 7257\n",
    "  \n",
    "Once you have it working, try looking at the frequencies of some other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try calc_frequencies() and get_frequency() here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `unique_words()`\n",
    "\n",
    "Finally, try out `unique_words()`:\n",
    "  * Call it with each of the two word lists you made above as its two arguments (whichever is put first is the one from which you will get unique words).\n",
    "  * Store its return value in a variable named `uniq`.\n",
    "  * Look at the first 20 words in the list by printing `uniq[:20]`.\n",
    "  \n",
    "You should see a list of 20 words that occur in the first book you chose but not the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try unique_words() here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Do some analysis\n",
    "\n",
    "Words that are found in one book and not in another are interesting, but they might not be *important* to the book.  For example, one of the words found in *A Tale of Two Cities* and not in *Pride and Prejudice* is \"exterior.\"  Okay, sure.\n",
    "\n",
    "So let's try to find words that are in one book and not in another *and occur frequently* in the first book.\n",
    "\n",
    "Here's the idea:\n",
    "\n",
    "1. Choose two books.\n",
    "2. Get the words and word-frequencies for each book chosen.\n",
    "3. Find the words that are unique to the first book and not in the second.\n",
    "\n",
    "   *[Until now, you've practiced this all above.]*\n",
    "5. For every word in the set of unique words:\n",
    "   1. Find its frequency within the first book.\n",
    "   2. If its frequency is above some lower limit: print out the word and its frequency.\n",
    "   \n",
    "A good lower limit to choose at first is 50.  That is, with a lower limit of 50, you will find all words that are only in the first book *and* occur at least 50 times in that book.\n",
    "\n",
    "**Caution:** if you set the lower limit *too* low, it will find and print out a *lot* of words.  If you lower it below 50, try 40 or 30 before you jump to 10 or something.\n",
    "\n",
    "Write and test code for those steps in the cell below.  You should end up with a list of frequent, unique words for the book chosen.  You might notice a common pattern in what type of words show up if you run your code with different books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and test your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, your output might look like this (you can probably guess which book this is analyzing):\n",
    "```\n",
    "Word: Hatter  frequency: 54\n",
    "Word: Queen  frequency: 67\n",
    "Word: Gryphon  frequency: 55\n",
    "Word: Alice  frequency: 385\n",
    "Word: Mock  frequency: 56\n",
    "Word: Turtle  frequency: 56\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Make it reusable\n",
    "\n",
    "In the code above, you have to **choose** three values: two book filenames and one lower limit on word frequency.  Everything else is calculated using those three values.\n",
    "\n",
    "That means we can make a **function** for the above code, and it would only need us to pass in three values as arguments.  If we do that, we have a reusable function that we can call easily with different arguments to run the code on multiple books or to try out different lower limits, and generally we can work with it much more easily as a function.\n",
    "\n",
    "Define a function in the cell below called `print_frequent_words()`:\n",
    "  * It should have three **parameters**: two filenames and one lower limit on the frequency\n",
    "  * It should use those three parameters to do the same thing the earlier analysis did\n",
    "  * It should print out the analysis results, just like the above code did.  It will therefore be a **void** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define print_frequent_words() here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function below by calling it multiple times with different filenames and different lower limits on word frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your print_frequent_words() function here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional consideration: More efficient code\n",
    "\n",
    "When dealing with large sets of data, it's important to think about how *efficient* the code is.  Every time we call the function above, it has to read both files specified and compute the frequencies of their words again.  If we call it multiple times, that is a lot of duplicate, redundant work!\n",
    "\n",
    "A better approach would be to separate out reading the data and calculating the frequencies from the work of finding frequent, unique words.  The function you might write then would have parameters for two word lists, two sets of frequencies, and the lower frequency limit.  The idea is you would have the word and frequency lists calculated and stored in variables, and you could just pass those variables into the function without having to recalculate them.\n",
    "\n",
    "If you'd like more practice, try writing and testing that variant of the function.  You might even notice that it runs faster than the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test your faster more efficient code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
