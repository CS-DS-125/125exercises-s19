{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing Files\n",
    "\n",
    "This contains a few exercises focused on reading and writing files.  It uses the same 311 data as earlier exercises.\n",
    "\n",
    "Relevant textbook section: [5.3 - Files](https://snakebear.science/05-StringsListsAndFiles/Files.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the following steps builds on the previous.  For each, copy your code from the previous step and modify or add to it to achieve the additional goals in the new step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Open a file and find weird entries\n",
    "\n",
    "Data often contains weird things.  In the 311 data, there are a lot of incomplete entries or data that wasn't entered correctly.  We had to write a fair amount of code just to filter those out to do an analysis.  A first step in dealing with that is *finding* the weird/messy data.\n",
    "\n",
    "Here, we'll look for entries containing the string ``'XXXX'``.\n",
    "\n",
    "1. Open the file `311_Service_Requests_-_Abandoned_Vehicles_-_No_Duplicates.csv`.\n",
    "2. [Search through the file](https://snakebear.science/05-StringsListsAndFiles/Files.html#searching-through-a-file) using a for loop and a conditional to find any lines containing ``'XXXX'``.\n",
    "    - Refer to [the final example](https://snakebear.science/05-StringsListsAndFiles/Files.html#files11) in the linked section.\n",
    "    - Use ``line.find()``.  For example:\n",
    "```\n",
    "          if line.find('XXXX') != -1:\n",
    "              # this body will execute if the line does contain 'XXXX'\n",
    "```\n",
    "3. For any lines containing ``'XXXX'``, add 1 to a counter variable ``weird_count``.\n",
    "4. Print out the value of ``weird_count`` when done.  It should be 113."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 weird lines found.\n"
     ]
    }
   ],
   "source": [
    "weird_count = 0  # count of weird lines\n",
    "\n",
    "with open('311_Service_Requests_-_Abandoned_Vehicles_-_No_Duplicates.csv') as file:\n",
    "    for line in file:\n",
    "        if line.find('XXXX') != -1:\n",
    "            weird_count = weird_count + 1\n",
    "\n",
    "print(weird_count, \"weird lines found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Store weird entries in their own file\n",
    "\n",
    "Now that you've found the weird entries, it might be useful to store them in their own file for further inspection and processing.\n",
    "\n",
    "Copy your code from the previous part, and modify it to:\n",
    "\n",
    "1. [Open a new file for writing](https://snakebear.science/05-StringsListsAndFiles/Files.html#writing-files) called ``311_weird.csv``.\n",
    "   - To do this you might need to open two files simultaneously, because you will also need to read from the original data file.\n",
    "2. For any 'weird' line found (as in Part 1), write that line into ``311_weird.csv``.\n",
    "\n",
    "Open the new file (double-click on it in the file browser on the left) to check that it contains 113 lines, all containing ``'XXXX'`` somewhere.  (It might look like 112 lines, but the first line is being used as a header in Jupyterhub's viewer, so it doesn't get numbered.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('311_weird.csv', 'w') as file_out:\n",
    "    with open('311_Service_Requests_-_Abandoned_Vehicles_-_No_Duplicates.csv') as file:\n",
    "        for line in file:\n",
    "            if line.find('XXXX') != -1:\n",
    "                file_out.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Write a \"cleaned\" version of the file.\n",
    "\n",
    "It is also common to want to produce a \"clean\" version of some data, with entries you don't want to use removed.  It is important to store this in a **new** file, so that the original file is preserved.  Preserving the original data allows you or anyone else to **reproduce** your work by re-running your code on the original data.\n",
    "\n",
    "Copy your code from the previous part, and modify it to:\n",
    "\n",
    "1. Open a new file for writing called ``311_clean.csv``.  (This code doesn't need to open ``311_weird.csv`` any more.)\n",
    "2. As you loop through the lines of the input file, use ``continue`` as shown in the textbook to **skip** any 'weird' lines, where 'weird' here means any of the following:\n",
    "   1. The line contains ``'XXXX'``\n",
    "   2. The line, when split into a list on the comma character, has fewer than 17 entries.  (Most lines contain 17 values.  A few do not.)\n",
    "      - To split the line, use:\n",
    "      ```\n",
    "            entries = line.split(',')\n",
    "      ```\n",
    "   3. The entry at index 10 in ``entries`` is not numeric.  (Index 10 should be a number of days.  If it doesn't hold a number, then we'll treat it as invalid data.)\n",
    "      - Write a conditional using:\n",
    "      ```\n",
    "            not entries[10].isnumeric()\n",
    "      ```\n",
    "3. For any lines *not* skipped, write them into the ``311_cleaned.csv`` file.\n",
    "4. Count the number of lines written into ``311_cleaned.csv`` and print out the count.\n",
    "\n",
    "**Tip:** Start with just one step of filtering, get it working, and then add the next two, one at a time.\n",
    "\n",
    "The final count should be 146383."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146383 lines written to 311_clean.csv.\n"
     ]
    }
   ],
   "source": [
    "good_count = 0   # number of good lines written into 311_clean.csv\n",
    "\n",
    "with open('311_clean.csv', 'w') as file_out:\n",
    "    with open('311_Service_Requests_-_Abandoned_Vehicles_-_No_Duplicates.csv') as file:\n",
    "        for line in file:\n",
    "            # Skip lines with 'XXXX'\n",
    "            if line.find('XXXX') != -1:\n",
    "                continue\n",
    "            \n",
    "            entries = line.split(',')\n",
    "            # Skip lines with < 17 values\n",
    "            if len(entries) < 17:\n",
    "                continue\n",
    "            \n",
    "            # Skip lines where the value at index 10 is not numeric\n",
    "            if not entries[10].isnumeric():\n",
    "                continue\n",
    "            \n",
    "            # If we get here, none of the checks above were triggered and the line is \"clean\"\n",
    "            file_out.write(line)\n",
    "            good_count = good_count + 1\n",
    "\n",
    "print(good_count, \"lines written to 311_clean.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "And that's it for this exercise.  With the cleaned data, you could write an analysis program with fewer checks for bad data, making it cleaner and easier to understand.  Separating out the cleaning from the analysis makes each part easier to work with and more reusable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
